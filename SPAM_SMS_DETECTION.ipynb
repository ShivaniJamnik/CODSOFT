{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MSy2AnzIxzsE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Unzip the dataset\n",
        "zip_file_path = '/content/archive (7).zip'\n",
        "extract_folder = 'sms_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n"
      ],
      "metadata": {
        "id": "0whP86tny1uL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sms_data/spam.csv', encoding='latin-1')"
      ],
      "metadata": {
        "id": "P4WyaQx5x3NH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few rows of the dataframe\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Clean the Data\n",
        "# Drop unnecessary columns if they exist\n",
        "if 'Unnamed: 2' in df.columns:\n",
        "    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "# Map labels to binary values\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X = df['message']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coQ2GcJTx3Ud",
        "outputId": "64b5a298-2037-4e45-ced7-1f6301fabb6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "Accuracy: 0.967713004484305\n",
            "Confusion Matrix:\n",
            " [[964   1]\n",
            " [ 35 115]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       0.99      0.77      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the MultinomialNB classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Import the SVC class\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define a function to train and evaluate models\n",
        "def train_and_evaluate(model, model_name):\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Train and evaluate Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "train_and_evaluate(nb_model, \"Naive Bayes\")\n",
        "\n",
        "# Train and evaluate Logistic Regression\n",
        "lr_model = LogisticRegression()\n",
        "train_and_evaluate(lr_model, \"Logistic Regression\")\n",
        "\n",
        "# Train and evaluate Support Vector Machine\n",
        "svm_model = SVC() # Call the SVC class after importing it\n",
        "train_and_evaluate(svm_model, \"Support Vector Machine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8je2utyx3Ya",
        "outputId": "1812a18e-2da4-4525-8da6-87f80b4f887b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "Accuracy: 0.9623318385650225\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 42 108]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.72      0.84       150\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.98      0.86      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n",
            "--------------------------------------------------\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.967713004484305\n",
            "Confusion Matrix:\n",
            " [[964   1]\n",
            " [ 35 115]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       0.99      0.77      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "--------------------------------------------------\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.9820627802690582\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 20 130]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       1.00      0.87      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.93      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data_file_path = '/content/sms_data/spam.csv'\n",
        "df = pd.read_csv(data_file_path, encoding='latin-1')\n",
        "\n",
        "# Clean the Data\n",
        "if 'Unnamed: 2' in df.columns:\n",
        "    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "df.columns = ['label', 'message']\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df['message']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Define a function to train and evaluate models\n",
        "def train_and_evaluate(model, model_name):\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Train and evaluate Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "train_and_evaluate(nb_model, \"Naive Bayes\")\n",
        "\n",
        "# Train and evaluate Logistic Regression\n",
        "lr_model = LogisticRegression()\n",
        "train_and_evaluate(lr_model, \"Logistic Regression\")\n",
        "\n",
        "# Train and evaluate Support Vector Machine\n",
        "svm_model = SVC()\n",
        "train_and_evaluate(svm_model, \"Support Vector Machine\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URtTEeXIx3bL",
        "outputId": "ba3177d6-bf6b-4a33-9294-32d573c5bbca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "Accuracy: 0.9623318385650225\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 42 108]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.72      0.84       150\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.98      0.86      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n",
            "--------------------------------------------------\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.967713004484305\n",
            "Confusion Matrix:\n",
            " [[964   1]\n",
            " [ 35 115]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       0.99      0.77      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "--------------------------------------------------\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.9820627802690582\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 20 130]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       1.00      0.87      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.93      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data_file_path = '/content/sms_data/spam.csv'  # Adjust this path if necessary\n",
        "df = pd.read_csv(data_file_path, encoding='latin-1')\n",
        "\n",
        "# Step 2: Clean the Data\n",
        "# Drop unnecessary columns if they exist\n",
        "if 'Unnamed: 2' in df.columns:\n",
        "    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "# Map labels to binary values (0 for ham, 1 for spam)\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X = df['message']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Define a function to train and evaluate models\n",
        "def train_and_evaluate(model, model_name):\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Step 6: Train and evaluate Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "train_and_evaluate(nb_model, \"Naive Bayes\")\n",
        "\n",
        "# Step 7: Train and evaluate Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)  # Increase max_iter for convergence\n",
        "train_and_evaluate(lr_model, \"Logistic Regression\")\n",
        "\n",
        "# Step 8: Train and evaluate Support Vector Machine\n",
        "svm_model = SVC()\n",
        "train_and_evaluate(svm_model, \"Support Vector Machine\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYv-KTKBx3eF",
        "outputId": "92b7e256-628d-4494-e66c-1eab9796b423"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "Accuracy: 0.9623318385650225\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 42 108]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.72      0.84       150\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.98      0.86      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n",
            "--------------------------------------------------\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.967713004484305\n",
            "Confusion Matrix:\n",
            " [[964   1]\n",
            " [ 35 115]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       0.99      0.77      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "--------------------------------------------------\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.9820627802690582\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 20 130]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       1.00      0.87      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.93      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(nb_model, 'spam_detection_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j2pwKCUx3hE",
        "outputId": "be8d599a-9777-4bb0-97c0-08e5430957a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}